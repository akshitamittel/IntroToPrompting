{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b07abc88",
   "metadata": {},
   "source": [
    "# Registering your API Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9818173",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from registered_keys import openapi_key\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = openapi_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b46906",
   "metadata": {},
   "source": [
    "# Components of a basic prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91984482",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI\n",
    "\n",
    "llm = OpenAI(temperature=1)\n",
    "prediction = llm.invoke(\n",
    "    \"\"\"Suggest a weekend getaway place near the city of my choice.\n",
    "    ###city: San Francisco\n",
    "    ###Getaway place:\"\"\")\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ba8135",
   "metadata": {},
   "source": [
    "## Making prompts more specific"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830cca3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0.9)\n",
    "prediction = llm.invoke(\"Suggest a weekend getaway place near the city of my choice. Only output name of the place. ###city: San Francisco ###Getaway place:\")\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43a8d57",
   "metadata": {},
   "source": [
    "# Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6289a9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables =['city'],\n",
    "    template = \"\"\"\n",
    "    Suggest a weekend getaway place near the city of my choice. Only output name of the place.\n",
    "    ###city: {city}\n",
    "    ###Getaway place:\"\"\"\n",
    ")\n",
    "prompt = prompt_template.format(city = \"San Francisco\")\n",
    "\n",
    "print(llm.predict(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c80598",
   "metadata": {},
   "source": [
    "## Adding multiple variables to the template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d904a42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = PromptTemplate(\n",
    "    input_variables =['city', 'days'],\n",
    "    template = \"\"\"\n",
    "    Suggest a {days} day getaway place near the city of my choice. Only output name of the place.\n",
    "    ###city: {city}\n",
    "    ###Getaway place:\"\"\"\n",
    ")\n",
    "prompt = prompt_template.format(days=5, city=\"San Francisco\")\n",
    "\n",
    "print(llm.invoke(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80253cc",
   "metadata": {},
   "source": [
    "# Chaining with LLMChains\n",
    "## Example 1: Prompt chain with new prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09517d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "destination_prompt_template = PromptTemplate(\n",
    "    input_variables =['city'],\n",
    "    template = \"Suggest a weekend getaway place near the {city} of my choice. Only output name of the place. ###city: {city} ###Getaway place:\"\n",
    ")\n",
    "\n",
    "destination_chain = LLMChain(llm=llm, prompt=destination_prompt_template)\n",
    "\n",
    "itinerary_prompt_template = PromptTemplate(\n",
    "    input_variables =['destination'],\n",
    "    template = \"Based on the {destination} and days suggest an itinerary\"\n",
    ")\n",
    "\n",
    "itinerary_chain = LLMChain(llm=llm, prompt=itinerary_prompt_template)\n",
    "\n",
    "chain = SimpleSequentialChain(chains = [destination_chain, itinerary_chain])\n",
    "\n",
    "content = chain.invoke(\"San Francisco\")\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdab97bd",
   "metadata": {},
   "source": [
    "## Example 2: How to take more than one input? A deeper dive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f82daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "\n",
    "# Define the prompt to suggest a destination based on the city and number of days\n",
    "destination_prompt = PromptTemplate(\n",
    "    input_variables=[\"city\", \"days\"],\n",
    "    template=\"Suggest a {days} day getaway place near the {city} of my choice. Only output the name of the place. ###city: {city} ###Getaway place:\"\n",
    ")\n",
    "\n",
    "# Create the destination chain to use the LLM for suggesting a destination\n",
    "destination_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=destination_prompt,\n",
    "    output_key=\"destination\"\n",
    ")\n",
    "\n",
    "# Define the prompt to generate an itinerary based on the destination and number of days\n",
    "itinerary_prompt = PromptTemplate(\n",
    "    input_variables=[\"destination\", \"days\"],\n",
    "    template=\"Suggest names of places to visit on each day for {days} days to {destination}.\"\n",
    ")\n",
    "\n",
    "# Create the itinerary chain to use the LLM for generating an itinerary\n",
    "itinerary_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=itinerary_prompt,\n",
    "    output_key=\"itinerary\"\n",
    ")\n",
    "\n",
    "# Combine the chains into a SequentialChain\n",
    "e2e_chain = SequentialChain(\n",
    "    chains=[destination_chain, itinerary_chain],\n",
    "    input_variables=[\"city\", \"days\"],\n",
    "    output_variables=[\"destination\", \"itinerary\"],\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Function to plan the weekend getaway using the e2e chain\n",
    "def plan_weekend_getaway(city, days):\n",
    "    inputs = {\"city\": city, \"days\": days}\n",
    "    result = e2e_chain.invoke(inputs)\n",
    "    destination = result[\"destination\"].strip()\n",
    "    itinerary = result[\"itinerary\"].strip()\n",
    "    print(f\"Suggested Destination: {destination}\")\n",
    "    print(f\"Suggested Itinerary:\\n{itinerary}\")\n",
    "    \n",
    "plan_weekend_getaway(\"San Francisco\", 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab396af",
   "metadata": {},
   "source": [
    "# Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cab98d1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb144bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=destination_prompt_template)\n",
    "name = chain.invoke(\"Pittsburgh\")\n",
    "print(\"memory: \", chain.memory)\n",
    "print(\"memory type: \", type(chain.memory))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9edee459",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory()\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=destination_prompt_template, memory=memory)\n",
    "destination = chain.invoke(\"New York\")\n",
    "print(destination)\n",
    "\n",
    "destination = chain.invoke(\"New Delhi\")\n",
    "print(destination)\n",
    "\n",
    "print(chain.memory.buffer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "7500c3e1c7c786e4ba1e4b4eb7588219b4e35d5153674f92eb3a82672b534f6e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
